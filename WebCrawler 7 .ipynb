{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMAcLV9UFPp/sBhlyPLTEC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Darshini-A/Social-Network-Analysis/blob/main/WebCrawler%207%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RZNMRCkACceI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "669e5944-7495-4652-9dfb-a6805771c465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Depth: 0 URL: https://en.wikipedia.org/wiki/India\n",
            "Depth: 1 URL: https://en.wikipedia.org/wiki/India#bodyContent\n",
            "Depth: 2 URL: https://en.wikipedia.org/wiki/Main_Page\n",
            "Depth: 3 URL: https://en.wikipedia.org/wiki/Main_Page#bodyContent\n",
            "Depth: 4 URL: https://en.wikipedia.org/wiki/Wikipedia:Contents\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin, urlparse\n",
        "\n",
        "class WebCrawler:\n",
        "    def __init__(self, seed_url, max_depth=5, domain=None):\n",
        "        self.seed_url = seed_url\n",
        "        self.max_depth = max_depth\n",
        "        self.visited_urls = set()\n",
        "        self.domain = domain if domain else urlparse(seed_url).netloc\n",
        "        self.should_stop = False  # Flag to indicate whether to stop crawling\n",
        "\n",
        "    def crawl(self, url, depth=0):\n",
        "        if self.should_stop:  # Check if the flag is set to stop crawling\n",
        "            return\n",
        "        if depth >= self.max_depth:\n",
        "            self.should_stop = True  # Set the flag to stop crawling\n",
        "            return\n",
        "        if url in self.visited_urls:\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            response = requests.get(url)\n",
        "            if response.status_code == 200:\n",
        "                print(\"Depth:\", depth, \"URL:\", url)\n",
        "                self.visited_urls.add(url)\n",
        "\n",
        "                soup = BeautifulSoup(response.content, 'html.parser')\n",
        "                links = soup.find_all('a', href=True)\n",
        "                for link in links:\n",
        "                    next_url = urljoin(url, link['href'])\n",
        "                    parsed_url = urlparse(next_url)\n",
        "                    if parsed_url.netloc == self.domain:\n",
        "                        self.crawl(next_url, depth=depth+1)  # Pass depth explicitly\n",
        "        except Exception as e:\n",
        "            print(\"Error:\", e)\n",
        "            self.should_stop = True  # Set the flag to stop crawling in case of an error\n",
        "\n",
        "seed_url = \"https://en.wikipedia.org/wiki/India\"\n",
        "crawler = WebCrawler(seed_url)\n",
        "crawler.crawl(seed_url)"
      ]
    }
  ]
}